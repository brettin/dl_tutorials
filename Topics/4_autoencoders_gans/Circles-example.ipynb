{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.datasets import make_circles"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### Helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def scatter(x, y=None):\n",
    "    if y is None:\n",
    "        plt.plot(x[:, 0], x[:, 1], 'ko', alpha=0.05)\n",
    "    else:\n",
    "        plt.plot(x[y == 0, 0], x[y == 0, 1], 'bo', alpha=0.5)        \n",
    "        plt.plot(x[y == 1, 0], x[y == 1, 1], 'ro', alpha=0.5)        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def plot_scatter(x, y=None):\n",
    "    plt.figure(figsize=(6, 6))\n",
    "    scatter(x, y)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### Training data (small)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# define noise distribution\n",
    "noise = 0.1\n",
    "factor = 0.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "x_train, y_train = make_circles(n_samples=10, noise=noise, factor=factor)\n",
    "plot_scatter(x_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### Test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "x_test, y_test = make_circles(n_samples=100, noise=noise, factor=factor)\n",
    "plot_scatter(x_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### Unlabeled data drawn from the same distribution (big)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "x, _ = make_circles(n_samples=10000, noise=noise, factor=factor)\n",
    "plot_scatter(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### Plot labeled and unlabled data in the same figure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(6, 6))\n",
    "scatter(x_train, y_train)\n",
    "#scatter(x_test, y_test)\n",
    "scatter(x)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### Build an autoencoder to train latent representation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "import keras\n",
    "from keras.layers import Input, Dense\n",
    "from keras.models import Model\n",
    "\n",
    "activation = 'tanh'\n",
    "input_vector = Input(shape=(2,))\n",
    "h = Dense(20, activation=activation)(input_vector)\n",
    "h = Dense(10, activation=activation)(h)\n",
    "h = Dense(4, activation=activation)(h)\n",
    "encoded = h\n",
    "\n",
    "h = Dense(10, activation=activation)(h)\n",
    "h = Dense(20, activation=activation)(h)\n",
    "h = Dense(2, activation=activation)(h)\n",
    "\n",
    "ae = Model(input_vector, h)\n",
    "ae.summary()\n",
    "\n",
    "encoded_input = Input(shape=(4,))\n",
    "decoder = Model(encoded_input, ae.layers[-1](ae.layers[-2](ae.layers[-3](encoded_input))))\n",
    "encoder = Model(input_vector, encoded)\n",
    "\n",
    "ae.compile(optimizer='rmsprop', loss='mse')\n",
    "\n",
    "ae.fit(x, x, batch_size=100, epochs=2, validation_split=0.1)\n",
    "\n",
    "x_train_latent = encoder.predict(x_train)\n",
    "x_test_latent = encoder.predict(x_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### Compare the performance of supervised and semi-supervised learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "c1 = RandomForestClassifier()\n",
    "c1.fit(x_train, y_train)\n",
    "s1 = c1.score(x_test, y_test)\n",
    "print('Supervised learning:      ', s1)\n",
    "\n",
    "c2 = RandomForestClassifier()\n",
    "c2.fit(x_train_latent, y_train)\n",
    "s2 = c2.score(x_test_latent, y_test)\n",
    "print('Semi-supervised learning: ', s2)\n",
    "\n",
    "c3 = RandomForestClassifier()\n",
    "c3.fit(np.hstack((x_train, x_train_latent)), y_train)\n",
    "s3 = c3.score(np.hstack((x_test, x_test_latent)), y_test)\n",
    "print('Combined learning:        ', s3)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
